{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style='color:indianred'>  Sentiment Analysis of Trump-related Tweets </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  1. Load required packages </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 3.6.3”\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 3.6.3”\n",
      "Attaching package: ‘tidyr’\n",
      "\n",
      "The following object is masked from ‘package:magrittr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "The following objects are masked from ‘package:Matrix’:\n",
      "\n",
      "    expand, pack, unpack\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(lattice)\n",
    "library(Matrix)\n",
    "library(caret)\n",
    "library(dplyr)\n",
    "library(magrittr)\n",
    "library(tidyr)\n",
    "library(tidytext)\n",
    "library(rtweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  2. Load dataset  </span>\n",
    "**rtweet library documentation:** https://www.rdocumentation.org/packages/rtweet/versions/0.7.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 method overwritten by 'openssl':\n",
      "  method      from\n",
      "  print.bytes Rcpp\n",
      "Warning message:\n",
      "“Rate limit exceeded - 88”Warning message:\n",
      "“Rate limit exceeded”"
     ]
    }
   ],
   "source": [
    "tweets_df <- search_tweets(\"@realdonaldtrump\", n = 2000, include_rts = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "<0 x 0 matrix>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  3. Prepare Dataframe and Check for NA </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>text:</strong> 0"
      ],
      "text/latex": [
       "\\textbf{text:} 0"
      ],
      "text/markdown": [
       "**text:** 0"
      ],
      "text/plain": [
       "text \n",
       "   0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df$text <- as.character(tweets_df$text)\n",
    "sapply(tweets_df, function(x) sum(is.na(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  4. Investigate Variables </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimr::skim(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  5. Tokenize by Word </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.tidy <- tidytext::unnest_tokens(tweets_df, word, text)\n",
    "head(dplyr::count(tweets_df.tidy, word, sort = TRUE),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  6. Remove Stopwords </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.clean <- dplyr::anti_join(tweets_df.tidy, tidytext::get_stopwords())\n",
    "tweets_df.clean <- tweets_df.clean[which(nchar(tweets_df.clean$word) > 2 &\n",
    "                                         tweets_df.clean$word != \"http\" & \n",
    "                                         tweets_df.clean$word != \"https\" &\n",
    "                                         tweets_df.clean$word != \"trump\" &\n",
    "                                         tweets_df.clean$word != \"trump's\" &\n",
    "                                         tweets_df.clean$word != \"donald\" &\n",
    "                                         tweets_df.clean$word != \"amp\" &\n",
    "                                         tweets_df.clean$word != \"justice\" &\n",
    "                                         tweets_df.clean$word != \"michael\" &\n",
    "                                         tweets_df.clean$word != \"flynn\" &\n",
    "                                         tweets_df.clean$word != \"general\" &\n",
    "                                         tweets_df.clean$word != \"yeah\" &\n",
    "                                         tweets_df.clean$word != \"realdonaldtrump\" &\n",
    "                                         tweets_df.clean$word != \"president\"),]\n",
    "tweets_df.count <- dplyr::count(tweets_df.clean, word, sort = TRUE)\n",
    "head(tweets_df.count, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  7. Visualize most common words </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.count$word <- reorder(tweets_df.count$word, tweets_df.count$n)\n",
    "\n",
    "ggplot2::ggplot(head(tweets_df.count, 20), ggplot2::aes(x = word, y = n)) +\n",
    "  ggplot2::geom_col() +\n",
    "  ggplot2::coord_flip() +\n",
    "  ggpubr::theme_pubclean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  8. Visualize as Word Cloud </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud::wordcloud(tweets_df.count$word, tweets_df.count$n, min.freq = 10, max.words = 100, random.order=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  9. Compute TF-IDF </span>\n",
    "We will use screen_name as document in this case. You could also use the tweet (i.e., text) instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.count <- dplyr::count(tweets_df.clean, screen_name, word, sort = TRUE) \n",
    "head(tidytext::bind_tf_idf(tweets_df.count, word, screen_name, n),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  10. Join Sentiment Dictionaries and Visualize Sentiment Counts </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.sen <- dplyr::inner_join(tweets_df.clean, tidytext::get_sentiments(\"nrc\"), by = \"word\")\n",
    "tweets_df.sen <- dplyr::inner_join(tweets_df.sen, tidytext::get_sentiments(\"afinn\"), by = \"word\")\n",
    "tweets_df.sen_count <- dplyr::count(tweets_df.sen, sentiment, word, sort = TRUE)\n",
    "tweets_df.sen_count$word <- reorder(tweets_df.sen_count$word, tweets_df.sen_count$n)\n",
    "tweets_df.sen_count <- by(tweets_df.sen_count, tweets_df.sen_count[\"sentiment\"], head, n=5)\n",
    "tweets_df.sen_count <- Reduce(rbind, tweets_df.sen_count)\n",
    "head(tweets_df.sen[,c('word','sentiment')],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot2::ggplot(tweets_df.sen_count, ggplot2::aes(x = word, y = n, fill = sentiment)) +\n",
    "  ggplot2::geom_col(show.legend = FALSE) +\n",
    "  ggplot2::facet_wrap(~sentiment, scales = \"free\") +\n",
    "  ggplot2::labs(y = \"Contribution to sentiment\", x = NULL) +\n",
    "  ggplot2::coord_flip() +\n",
    "  ggpubr::theme_pubclean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style='color:tomato'>  11. Visualize Sentiment Analysis </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.sen_count <- aggregate(n ~ sentiment, tweets_df.sen_count, sum)\n",
    "tweets_df.sen_count$sentiment <- reorder(tweets_df.sen_count$sentiment, tweets_df.sen_count$n)\n",
    "\n",
    "ggplot2::ggplot(tweets_df.sen_count, ggplot2::aes(x = sentiment, y = n, fill = sentiment)) +\n",
    "  ggplot2::geom_col(show.legend = FALSE) +\n",
    "  ggplot2::coord_flip() +\n",
    "  ggpubr::theme_pubclean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style='color:tomato'>  12. Compute Word Pairs and Correlations </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pair <- widyr::pairwise_count(tweets_df.clean, word, screen_name, sort = TRUE)\n",
    "head(word_pair, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cor <- widyr::pairwise_cor(tweets_df.clean[sample(nrow(tweets_df.clean), 1000),], word, screen_name, sort = TRUE)\n",
    "correlations <- word_cor[which(word_cor$correlation != 1),]\n",
    "head(correlations,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result <- filter(correlations, item1 == \"apologize\")\n",
    "head(result,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
